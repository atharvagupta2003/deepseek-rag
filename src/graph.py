import os
from langchain_ollama import ChatOllama
from typing import List, Optional
from typing_extensions import TypedDict
from langchain_core.messages import BaseMessage
from langgraph.graph.message import add_messages
from langchain.tools.retriever import create_retriever_tool
from ingest import retriever
from langgraph.graph import StateGraph, END
from langchain.prompts import PromptTemplate
from langchain.chains import RetrievalQA
from langchain_openai import ChatOpenAI
from langchain.schema import Document

class GraphState(TypedDict):
    """
    Graph state that tracks the flow of the retrieval-augmented generation (RAG) process.

    Attributes:
        question (str): The user query.
        retrieved_docs (List[BaseMessage]): List of retrieved documents from the retriever.
        final_answer (Optional[str]): The final response generated by the LLM.
    """
    question: str
    retrieved_docs: List[BaseMessage]
    final_answer: Optional[str]


# model = ChatOpenAI(model="gpt-4o")
model = ChatOllama(model="deepseek-llm:7b")

retriever_tool = create_retriever_tool(
    retriever,
    "retrieve_blog_posts",
    "Search and return information about Lilian Weng blog posts on LLM agents, prompt engineering, and adversarial attacks on LLMs.",
   )

tools = [retriever_tool]


#Nodes

def retrieve_documents(state: GraphState) -> GraphState:
    """Retrieves relevant documents using the retriever tool."""
    query = state["question"]
    retrieved_docs = retriever_tool.invoke(query)  # This returns a list of strings

    # Convert raw strings into Document objects
    if isinstance(retrieved_docs, list) and all(isinstance(doc, str) for doc in retrieved_docs):
        retrieved_docs = [Document(page_content=doc) for doc in retrieved_docs]

    state["retrieved_docs"] = retrieved_docs  # Store formatted Document objects
    return state

# 游릭 Define answer generation node
def generate_answer(state: GraphState) -> GraphState:
    """Generates an answer using retrieved documents; otherwise, says 'I don't know'."""
    
    # Debugging print
    print(f"游댌 Retrieved Docs: {state['retrieved_docs']}")

    if not state["retrieved_docs"]:  
        state["final_answer"] = "I don't know."
    else:
        # Ensure all documents have 'page_content'
        context = "\n\n".join(
            [doc.page_content for doc in state["retrieved_docs"] if hasattr(doc, 'page_content')]
        )

        # Define prompt
        prompt_template = PromptTemplate.from_template(
            "You are an assistant for question-answering tasks. "
            "Use the retrieved context below to answer the question. "
            "If you don't know the answer, say 'I don't know'. Keep responses brief.\n\n"
            "Context:\n{context}\n\n"
            "Question:\n{question}\n\n"
            "Answer:"
        )

        # Define RetrievalQA chain
        qa_chain = RetrievalQA.from_chain_type(
            llm=model,
            chain_type="stuff",
            retriever=retriever,
            chain_type_kwargs={"prompt": prompt_template}
        )

        # Generate answer
        state["final_answer"] = qa_chain.invoke({"query": state["question"], "context": context})

    return state

# 游릭 Define LangGraph workflow
graph = StateGraph(GraphState)
graph.add_node("retrieve_documents", retrieve_documents)
graph.add_node("generate_answer", generate_answer)

graph.set_entry_point("retrieve_documents")
graph.add_edge("retrieve_documents", "generate_answer")
graph.add_edge("generate_answer", END)

# 游릭 Compile the graph
graph = graph.compile()

# def run_agent(question: str) -> str:
#     """Runs the LangGraph agent with a given question."""
#     state: GraphState = {
#         "question": question,
#         "retrieved_docs": [],
#         "final_answer": None,
#     }
#     final_state = graph.invoke(state)
#     return final_state["final_answer"]

# # 游릭 Example Usage
# if __name__ == "__main__":
#     user_query = "What is WebGPT, and how does it improve browser-assisted question-answering?"
#     answer = run_agent(user_query)
#     print(f"游닇 Answer: {answer}") 
 